<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Blog Title</title><link>https://awsl12581.github.io/nongchatea.github.io</link><description>Blog description</description><copyright>Blog Title</copyright><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><image><url>https://github.githubassets.com/favicons/favicon.svg</url><title>avatar</title><link>https://awsl12581.github.io/nongchatea.github.io</link></image><lastBuildDate>Sun, 17 Nov 2024 02:42:10 +0000</lastBuildDate><managingEditor>Blog Title</managingEditor><ttl>60</ttl><webMaster>Blog Title</webMaster><item><title>windows下vscode+cuda+torch配置</title><link>https://awsl12581.github.io/nongchatea.github.io/post/windows-xia-vscode%2Bcuda%2Btorch-pei-zhi.html</link><description># 1.安装了pytorch的python虚拟环境&#13;
&#13;
![](https://cdn.nlark.com/yuque/0/2024/png/21764230/1728436575784-8e0fb0af-c4e4-484b-a7a9-3e96f07f8a66.png)&#13;
&#13;
# 2.cmake文件&#13;
&#13;
```cmake&#13;
cmake_minimum_required(VERSION 3.22)&#13;
project(paperscuda LANGUAGES CUDA CXX)&#13;
&#13;
set(CMAKE_EXPORT_COMPILE_COMMANDS ON )&#13;
set(CMAKE_CXX_STANDARD 17)&#13;
set(CMAKE_CXX_STANDARD_REQUIRED ON)&#13;
set(CMAKE_CXX_EXTENSIONS ON)&#13;
&#13;
# use cudnn for cuda &gt;12.0&#13;
# set(CAFFE2_USE_CUDNN 1)&#13;
set(CAFFE2_USE_CUDNN ON)&#13;
&#13;
# if(MSVC)&#13;
#     add_compile_options('/source-charset:utf-8')&#13;
#     add_compile_options('/execution-charset:gbk')&#13;
# endif(MSVC)&#13;
&#13;
&#13;
set(Python_ROOT_DIR '${CMAKE_SOURCE_DIR}/.venv')&#13;
&#13;
# find python Interpreter&#13;
# find_package(Python3 COMPONENTS Interpreter)&#13;
find_package(Python COMPONENTS Interpreter Development)&#13;
message(STATUS 'Python interpreter: ${Python_EXECUTABLE}')&#13;
&#13;
message(STATUS ${Python_INCLUDE_DIRS})&#13;
&#13;
include_directories(.)&#13;
&#13;
set(Torch_DIR ${Python_ROOT_DIR}/Lib/site-packages/torch/share/cmake/Torch)&#13;
find_package(Torch REQUIRED)&#13;
&#13;
message(STATUS ${CUDA_nvrtc_LIBRARY})&#13;
&#13;
add_executable(main main.cu)&#13;
# add_executable(matmul matmul.cu)&#13;
message(STATUS ${TORCH_LIBRARIES})&#13;
# lib link&#13;
target_link_libraries(main ${TORCH_LIBRARIES})&#13;
&#13;
# add dll to binary&#13;
# 定义lib文件夹路径&#13;
set(LIB_DIR ${Python_ROOT_DIR}/Lib/site-packages/torch/lib)&#13;
&#13;
# 设置目标二进制输出目录&#13;
set(BINARY_DIR ${PROJECT_BINARY_DIR})&#13;
&#13;
# 查找所有 .dll 文件，排除 .lib 文件&#13;
file(GLOB DLL_FILES '${LIB_DIR}/*.dll')&#13;
&#13;
# 添加自定义命令，在 POST_BUILD 阶段执行&#13;
add_custom_command(TARGET main POST_BUILD&#13;
    COMMAND ${CMAKE_COMMAND} -E make_directory ${BINARY_DIR}  # 确保目标目录存在&#13;
    COMMAND ${CMAKE_COMMAND} -E copy_if_different ${DLL_FILES} ${BINARY_DIR}  # 复制所有 .dll 文件到目标目录&#13;
)&#13;
# add_library(paperscuda SHARED library.cu)&#13;
&#13;
# set_target_properties(main PROPERTIES&#13;
#         CUDA_SEPARABLE_COMPILATION ON)&#13;
&#13;
```&#13;
&#13;
main.cu&#13;
&#13;
```cpp&#13;
#include &lt;iostream&gt;&#13;
#include &lt;cuda_runtime.h&gt;&#13;
#include 'device_launch_parameters.h'&#13;
#include &lt;torch/torch.h&gt; // libtorch&#13;
&#13;
using namespace torch; // libtorch&#13;
using namespace std;&#13;
&#13;
__global__ void matmul_gpu(float *A, float *B, float *C, int m, int k, int n)&#13;
{&#13;
    int row = blockIdx.y * blockDim.y + threadIdx.y;&#13;
    int col = blockIdx.x * blockDim.x + threadIdx.x;&#13;
&#13;
    if (row &lt; m &amp;&amp; col &lt; n)&#13;
    {&#13;
        float sum = 0.0f;&#13;
        for (int l = 0; l &lt; k; l++)&#13;
        {&#13;
            sum += A[row * k + l] * B[l * n + col];&#13;
        }&#13;
        C[row * n + col] = sum;&#13;
    }&#13;
}&#13;
&#13;
int main()&#13;
{&#13;
    cout &lt;&lt; torch::cuda::is_available() &lt;&lt; endl;&#13;
    cout &lt;&lt; torch::cuda::cudnn_is_available() &lt;&lt; endl;&#13;
    cout &lt;&lt; torch::cuda::device_count() &lt;&lt; endl;&#13;
    return 0;&#13;
}&#13;
```&#13;
&#13;
一个合适的cmake编译输出文件：&#13;
&#13;
```plain&#13;
[main] 正在配置项目: paperscuda &#13;
[proc] 执行命令: 'C:\Program Files\CMake\bin\cmake.EXE' -DCMAKE_BUILD_TYPE:STRING=Debug -DCMAKE_EXPORT_COMPILE_COMMANDS:BOOL=TRUE --no-warn-unused-cli -SD:/GitHub/paperscuda -Bd:/GitHub/paperscuda/build -G Ninja&#13;
[cmake] Not searching for unused variables given on the command line.&#13;
[cmake] -- Python interpreter: D:/GitHub/paperscuda/.venv/Scripts/python.exe&#13;
[cmake] -- C:/Users/Administrator/AppData/Local/Programs/Python/Python310/include&#13;
[cmake] -- Caffe2: CUDA detected: 12.6&#13;
[cmake] -- Caffe2: CUDA nvcc is: C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v12.6/bin/nvcc.exe&#13;
[cmake] -- Caffe2: CUDA toolkit directory: C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v12.6&#13;
[cmake] -- Caffe2: Header version is: 12.6&#13;
[cmake] -- C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v12.6/lib/x64/nvrtc.lib shorthash is bac8224f&#13;
[cmake] -- USE_CUSPARSELT is set to 0. Compiling without cuSPARSELt support&#13;
[cmake] -- Autodetected CUDA architecture(s):  6.1&#13;
[cmake] -- Added CUDA NVCC flags for: -gencode;arch=compute_61,code=sm_61&#13;
[cmake] -- C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v12.6/lib/x64/nvrtc.lib&#13;
[cmake] -- torchtorch_libraryD:/GitHub/paperscuda/.venv/Lib/site-packages/torch/lib/c10.libD:/GitHub/paperscuda/.venv/Lib/site-packages/torch/lib/kineto.libC:\Program Files\NVIDIA Corporation\NvToolsExt\/lib/x64/nvToolsExt64_1.libC:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v12.6/lib/x64/cudart_static.libD:/GitHub/paperscuda/.venv/Lib/site-packages/torch/lib/caffe2_nvrtc.libD:/GitHub/paperscuda/.venv/Lib/site-packages/torch/lib/c10_cuda.lib&#13;
[cmake] -- Configuring done (8.6s)&#13;
[cmake] -- Generating done (0.0s)&#13;
[cmake] -- Build files have been written to: D:/GitHub/paperscuda/build&#13;
```&#13;
&#13;
# 3.补充说明&#13;
&#13;
## 1.关于find_package(Python3 COMPONENTS Interpreter)&#13;
&#13;
导入torch需要查找到python解释器和库的位置（这来源于caffe需要借助python来计算库文件的hash值），在启用了virtualvenv时，我们希望找到venv的解释器地址。</description><guid isPermaLink="true">https://awsl12581.github.io/nongchatea.github.io/post/windows-xia-vscode%2Bcuda%2Btorch-pei-zhi.html</guid><pubDate>Sun, 17 Nov 2024 02:41:48 +0000</pubDate></item><item><title>这是一个测试</title><link>https://awsl12581.github.io/nongchatea.github.io/post/zhe-shi-yi-ge-ce-shi.html</link><description># 测试文件&#13;
&#13;
Hello,Pages!。</description><guid isPermaLink="true">https://awsl12581.github.io/nongchatea.github.io/post/zhe-shi-yi-ge-ce-shi.html</guid><pubDate>Sun, 17 Nov 2024 02:26:53 +0000</pubDate></item></channel></rss>